{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a TensorNode class to insert a network built with the Tensorflow Keras API into a Nengo model\n",
    "This tutorial builds on [Inserting a TensorFlow network into a Nengo model](https://www.nengo.ai/nengo-dl/examples/pretrained-model.html). In that tutorial, we showed how to write a TensorNode class that makes it easy to insert a pre-trained network from `tf.contrib.slim` into a Nengo model.  \n",
    "Sometimes, instead of using a pre-trained network, you may want to use your own neural net architecture within a TensorNode. Here we show how a network built with the `tf.keras` API can be inserted into a Nengo model using the TensorNode class. If you haven't read the previous tutorial, please work through that one to familiarize yourself with the concept we'll use here. This tutorial also assumes familiarity with the `tf.keras` API. Specifically it is based on the [introduction in the Tensorflow documentation](https://www.tensorflow.org/tutorials/keras/basic_classification), so if you are not yet familiar with Keras, you may find it helpful to read those tutorials first as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import nengo\n",
    "import nengo_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train a neural network to classify the fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "num_classes = np.unique(test_labels).shape[0]  # there's 10, just like MNIST\n",
    "\n",
    "# normalize images so values are between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build and train a very simple fully-connected neural network, using the Keras API to work with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "            keras.layers.Dense(128, activation=tf.nn.relu, name='hidden'),\n",
    "            keras.layers.Dense(num_classes, activation=tf.nn.softmax, name='softmax')\n",
    "        ])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained weights. This way, as in the previous tutorial, we can load them in the `post_build` method of the class that we'll use inside our `TensorNode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('fully_connected_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the [first `TensorNode` tutorial](https://www.nengo.ai/nengo-dl/examples/pretrained-model.html), we write a class with a `pre_build` method that specifies the structure of our neural network, this time doing so with the high-level Keras API (by literally cutting and pasting the code we used to define our network when training it). We also use the `post_build` method where we can load the weights, after our network has been built as a dataflow graph that `Tensorflow` can execute within its C++ runtime. And again as before we provide a `__call__` method that gets executed at each timestep of our simulation that will be run with Nengo.\n",
    "\n",
    "Notice that in the `__call__` method, we simply pass our input tensor to the Keras model *without* calling a method such as `Model.predict` that you might intuitively write if you frequently work with the Keras API. We do this because we want the model to return a `Tensor` object, not computed predictions, i.e. a Numpy array of floats. This way the returned `Tensor` can become part of the dataflow graph that Tensorflow creates for its C++ runtime when acting as the Nengo backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = 'fully_connected_weights.h5'\n",
    "image_shape = (28, 28)\n",
    "\n",
    "class FullyConnectedNode:\n",
    "    def pre_build(self, *args):\n",
    "        self.model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=image_shape),\n",
    "            keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "            keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        ])\n",
    "\n",
    "    def post_build(self, sess, rng):\n",
    "        self.model.load_weights(model_weights)\n",
    "\n",
    "    def __call__(self, t, x):\n",
    "        images = tf.reshape(x, (-1,) + image_shape)\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the difference between just writing `model(images)` and `model.predict(images)`, you can read and/or run the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = 'fully_connected_weights.h5'\n",
    "image_shape = (28, 28)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "            keras.layers.Dense(128, activation=tf.nn.relu, name='hidden'),\n",
    "            keras.layers.Dense(10, activation=tf.nn.softmax, name='softmax')\n",
    "        ])\n",
    "    model.load_weights('fully_connected_weights.h5')\n",
    "    out1 = model(tf.convert_to_tensor(test_images[:10], dtype=tf.float32))\n",
    "    out2 = model.predict(test_images[:10])\n",
    "\n",
    "print(\"Type of 'out1': \", type(out1))\n",
    "print(\"Type of 'out2': \", type(out2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our `FullyConnectedNode` class, we can use it to insert our fully-connected Keras model into a Nengo network via a `TensorNode`.\n",
    "\n",
    "Notice here that we use a numpy `ones` vector as a dummy `output` from our `input_node`; it  will be replaced by our Fashion MNIST images, flattened into vectors, when we run the `Simulator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input_shape = np.prod(image_shape)  # because input will be a vector\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    # create a normal input node to feed in our test image\n",
    "    input_node = nengo.Node(output=np.ones((net_input_shape,)),\n",
    "                                           label='input')\n",
    "\n",
    "    # create our TensorNode containing the FullyConnectedNode() we defined\n",
    "    # above.  we also need to specify size_in (the dimensionality of\n",
    "    # our input vectors, the flattened images) and size_out (the number\n",
    "    # of classification classes output by the inception network)\n",
    "    fc_node = nengo_dl.TensorNode(\n",
    "        FullyConnectedNode(),\n",
    "        size_in=net_input_shape,\n",
    "        size_out=num_classes)\n",
    "\n",
    "    # connect up our input to our fully-connected network node\n",
    "    nengo.Connection(input_node, fc_node, synapse=None)\n",
    "\n",
    "    # add some probes to collect data\n",
    "    input_p = nengo.Probe(input_node)\n",
    "    fc_p = nengo.Probe(fc_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this very simple example, we only want to demonstrate *how* to insert your own Keras/Tensorflow style model in a Nengo network using a `TensorNode`, so we don't overcomplicate things by adding additional elements to the network. However, typically you would have Nengo ensembles of neurons with activity across time, and so the simulator expects to run for some number of time steps. We specify a number of time steps (even though in this case the output will be constant across time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also grab some images at random from our test set. Here we flatten them into vectors so we can pass them to the input node of our Nengo network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 20\n",
    "\n",
    "# flatten the test set so we can pass images as vectors to the input node\n",
    "test_images_flat = test_images.reshape([-1, np.prod(image_shape)])\n",
    "# grab some random images from test set\n",
    "test_inds = np.random.randint(low=0, high=test_images.shape[0],\n",
    "                              size=(minibatch_size,))\n",
    "# tile so that we have (minibatch size, time steps, images)\n",
    "minibatch = np.tile(test_images_flat[test_inds, None, :],(1, n_steps, 1))\n",
    "data = {input_node: minibatch}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = nengo_dl.Simulator(net, minibatch_size=minibatch_size)\n",
    "\n",
    "with sim:\n",
    "    sim.run_steps(n_steps, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the results of the simulation using the `probe` that we added to capture the output from the `TensorNode`, which we called `fc_p`. We use it as if it were a key and the `data` attribute of the simulator was a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensornode_output = sim.data[fc_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, the output from the `TensorNode` will be constant across time steps for each sample in the minibatch, since our Nengo network consists of just the `TensorNode` containing our simple fully-connected network. We can see this by taking the output for the first sample and finding the `argmax` for each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1_output = tensornode_output[0, :, :]\n",
    "np.argmax(sample_1_output, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't give us much intuition about whether our `TensorNode` is doing what we want, though.  \n",
    "To verify that the output on each time step matches what we'd get if we were running our network with Tensorflow, we can compare the output to the ground truth labels of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_step = tensornode_output[:,0,:]\n",
    "y_pred = np.argmax(first_time_step, axis=1)\n",
    "y_true = test_labels[test_inds]\n",
    "acc = np.sum(np.equal(y_pred, y_true)) / y_true.shape[0]\n",
    "print(f'Accuracy for minibatch: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a value that is close to the training accuracy we obtained above, which suggests our `TensorNode` is in fact running the forward pass through our fully-connected network on each time step.\n",
    "Now that you've gone through this tutorial, you're ready to integrate your own neural networks built with Keras and/or Tensorflow into Nengo models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [nengo-dl-dev]",
   "language": "python",
   "name": "Python [nengo-dl-dev]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
